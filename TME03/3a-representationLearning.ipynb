{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ben KABONGO**, *21116436*, M1 DAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP & representation learning: Neural Embeddings, Text Classification\n",
    "\n",
    "\n",
    "To use statistical classifiers with text, it is first necessary to vectorize the text. In the first practical session we explored the **Bag of Word (BoW)** model. \n",
    "\n",
    "Modern **state of the art** methods uses  embeddings to vectorize the text before classification in order to avoid feature engineering.\n",
    "\n",
    "## [Dataset](https://thome.isir.upmc.fr/classes/RITAL/json_pol)\n",
    "\n",
    "\n",
    "## \"Modern\" NLP pipeline\n",
    "\n",
    "By opposition to the **bag of word** model, in the modern NLP pipeline everything is **embeddings**. Instead of encoding a text as a **sparse vector** of length $D$ (size of feature dictionnary) the goal is to encode the text in a meaningful dense vector of a small size $|e| <<< |D|$. \n",
    "\n",
    "\n",
    "The raw classification pipeline is then the following:\n",
    "\n",
    "```\n",
    "raw text ---|embedding table|-->  vectors --|Neural Net|--> class \n",
    "```\n",
    "\n",
    "\n",
    "### Using a  language model:\n",
    "\n",
    "How to tokenize the text and extract a feature dictionnary is still a manual task. To directly have meaningful embeddings, it is common to use a pre-trained language model such as `word2vec` which we explore in this practical.\n",
    "\n",
    "In this setting, the pipeline becomes the following:\n",
    "```\n",
    "      \n",
    "raw text ---|(pre-trained) Language Model|--> vectors --|classifier (or fine-tuning)|--> class \n",
    "```\n",
    "\n",
    "\n",
    "- #### Classic word embeddings\n",
    "\n",
    " - [Word2Vec](https://arxiv.org/abs/1301.3781)\n",
    " - [Glove](https://nlp.stanford.edu/projects/glove/)\n",
    "\n",
    "\n",
    "- #### bleeding edge language models techniques (see next)\n",
    "\n",
    " - [UMLFIT](https://arxiv.org/abs/1801.06146)\n",
    " - [ELMO](https://arxiv.org/abs/1802.05365)\n",
    " - [GPT](https://blog.openai.com/language-unsupervised/)\n",
    " - [BERT](https://arxiv.org/abs/1810.04805)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Goal of this session:\n",
    "\n",
    "1. Train word embeddings on training dataset\n",
    "2. Tinker with the learnt embeddings and see learnt relations\n",
    "3. Tinker with pre-trained embeddings.\n",
    "4. Use those embeddings for classification\n",
    "5. Compare different embedding models\n",
    "6. Pytorch first look: learn to generate text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 0: Loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train reviews :  25000\n",
      "----> # of positive :  12500\n",
      "----> # of negative :  12500\n",
      "\n",
      "[\"The undoubted highlight of this movie is Peter O'Toole's performance. In turn wildly comical and terribly terribly tragic. Does anybody do it better than O'Toole? I don't think so. What a great face that man has!<br /><br />The story is an odd one and quite disturbing and emotionally intense in parts (especially toward the end) but it is also oddly touching and does succeed on many levels. However, I felt the film basically revolved around Peter O'Toole's luminous performance and I'm sure I wouldn't have enjoyed it even half as much if he hadn't been in it.\", 1]\n",
      "\n",
      "Number of test reviews :  25000\n",
      "----> # of positive :  12500\n",
      "----> # of negative :  12500\n",
      "\n",
      "['Although credit should have been given to Dr. Seuess for stealing the story-line of \"Horton Hatches The Egg\", this was a fine film. It touched both the emotions and the intellect. Due especially to the incredible performance of seven year old Justin Henry and a script that was sympathetic to each character (and each one\\'s predicament), the thought provoking elements linger long after the tear jerking ones are over. Overall, superior acting from a solid cast, excellent directing, and a very powerful script. The right touches of humor throughout help keep a \"heavy\" subject from becoming tedious or difficult to sit through. Lastly, this film stands the test of time and seems in no way dated, decades after it was released.', 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "# Loading json\n",
    "with open(\"ressources/json_pol\",encoding=\"utf-8\") as f:\n",
    "    data = f.readlines()\n",
    "    json_data = json.loads(data[0])\n",
    "    train = json_data[\"train\"]\n",
    "    test = json_data[\"test\"]\n",
    "    \n",
    "\n",
    "# Quick Check\n",
    "counter_train = Counter((x[1] for x in train))\n",
    "counter_test = Counter((x[1] for x in test))\n",
    "print(\"Number of train reviews : \", len(train))\n",
    "print(\"----> # of positive : \", counter_train[1])\n",
    "print(\"----> # of negative : \", counter_train[0])\n",
    "print(\"\")\n",
    "print(train[0])\n",
    "print(\"\")\n",
    "print(\"Number of test reviews : \",len(test))\n",
    "print(\"----> # of positive : \", counter_test[1])\n",
    "print(\"----> # of negative : \", counter_test[0])\n",
    "\n",
    "print(\"\")\n",
    "print(test[0])\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    punc = string.punctuation \n",
    "    punc += '\\n\\r\\t'\n",
    "    return text.translate(str.maketrans(punc, ' ' * len(punc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The undoubted highlight of this movie is Peter...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>More eeriness and dark secrets released in the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This was one of those films I probably never w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i love this film. the songs and story lines ar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I really truly enjoyed this movie. (Which is w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>\"Arahan\" adds nothing positive to the Kung Fu ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>I'm not sure quite why I clicked \"contains spo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>In fact, Marc Blitzstein's off-Broadway adapta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>(Spoilers galore) This is an absolutely awful ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>As a premise, this backwoods version of the De...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      The undoubted highlight of this movie is Peter...      1\n",
       "1      More eeriness and dark secrets released in the...      1\n",
       "2      This was one of those films I probably never w...      1\n",
       "3      i love this film. the songs and story lines ar...      1\n",
       "4      I really truly enjoyed this movie. (Which is w...      1\n",
       "...                                                  ...    ...\n",
       "24995  \"Arahan\" adds nothing positive to the Kung Fu ...      0\n",
       "24996  I'm not sure quite why I clicked \"contains spo...      0\n",
       "24997  In fact, Marc Blitzstein's off-Broadway adapta...      0\n",
       "24998  (Spoilers galore) This is an absolutely awful ...      0\n",
       "24999  As a premise, this backwoods version of the De...      0\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.DataFrame(train, columns=['text', 'label'])\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Although credit should have been given to Dr. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This was one of those films I would always com...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Man Who Knew Too Much{1956}is a remake of ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jamie Foxx does a fine job of impersonating th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/17/01 All I can do with this film is improv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>I wasn't impressed with the Graffiti Artist, d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>Here is a rundown of a typical Rachael Ray Sho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>Wow...not in a good way.&lt;br /&gt;&lt;br /&gt;I can't be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>This movie made me want to bang my head agains...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>Director Todd Verow's unexpected turn into sen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      Although credit should have been given to Dr. ...      1\n",
       "1      This was one of those films I would always com...      1\n",
       "2      The Man Who Knew Too Much{1956}is a remake of ...      1\n",
       "3      Jamie Foxx does a fine job of impersonating th...      1\n",
       "4      12/17/01 All I can do with this film is improv...      1\n",
       "...                                                  ...    ...\n",
       "24995  I wasn't impressed with the Graffiti Artist, d...      0\n",
       "24996  Here is a rundown of a typical Rachael Ray Sho...      0\n",
       "24997  Wow...not in a good way.<br /><br />I can't be...      0\n",
       "24998  This movie made me want to bang my head agains...      0\n",
       "24999  Director Todd Verow's unexpected turn into sen...      0\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame(test, columns=['text', 'label'])\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec: Quick Recap\n",
    "\n",
    "**[Word2Vec](https://arxiv.org/abs/1301.3781) is composed of two distinct language models (CBOW and SG), optimized to quickly learn word vectors**\n",
    "\n",
    "\n",
    "given a random text: `i'm taking the dog out for a walk`\n",
    "\n",
    "\n",
    "\n",
    "### (a) Continuous Bag of Word (CBOW)\n",
    "    -  predicts a word given a context\n",
    "    \n",
    "maximizing `p(dog | i'm taking the ___ out for a walk)`\n",
    "    \n",
    "### (b) Skip-Gram (SG)               \n",
    "    -  predicts a context given a word\n",
    "    \n",
    " maximizing `p(i'm taking the out for a walk | dog)`\n",
    "\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: train a language model (word2vec)\n",
    "\n",
    "Gensim has one of [Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html) fastest implementation.\n",
    "\n",
    "\n",
    "### Train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if gensim not installed yet\n",
    "# ! pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 00:09:38,413 : INFO : collecting all words and their counts\n",
      "2023-02-16 00:09:38,414 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-02-16 00:09:38,707 : INFO : PROGRESS: at sentence #10000, processed 2426102 words, keeping 61702 word types\n",
      "2023-02-16 00:09:39,011 : INFO : PROGRESS: at sentence #20000, processed 4816878 words, keeping 84298 word types\n",
      "2023-02-16 00:09:39,153 : INFO : collected 93201 word types from a corpus of 6022875 raw words and 25000 sentences\n",
      "2023-02-16 00:09:39,154 : INFO : Creating a fresh vocabulary\n",
      "2023-02-16 00:09:39,239 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 33359 unique words (35.79253441486679%% of original 93201, drops 59842)', 'datetime': '2023-02-16T00:09:39.239185', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2023-02-16 00:09:39,239 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 5924674 word corpus (98.36953282277982%% of original 6022875, drops 98201)', 'datetime': '2023-02-16T00:09:39.239596', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2023-02-16 00:09:39,351 : INFO : deleting the raw counts dictionary of 93201 items\n",
      "2023-02-16 00:09:39,352 : INFO : sample=0.001 downsamples 47 most-common words\n",
      "2023-02-16 00:09:39,354 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 4500851.640108086 word corpus (76.0%% of prior 5924674)', 'datetime': '2023-02-16T00:09:39.354262', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2023-02-16 00:09:39,577 : INFO : estimated required memory for 33359 words and 100 dimensions: 43366700 bytes\n",
      "2023-02-16 00:09:39,578 : INFO : resetting layer weights\n",
      "2023-02-16 00:09:39,591 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-02-16T00:09:39.591636', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2023-02-16 00:09:39,592 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 33359 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-02-16T00:09:39.592068', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2023-02-16 00:09:40,625 : INFO : EPOCH 1 - PROGRESS: at 9.78% examples, 434529 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:09:41,631 : INFO : EPOCH 1 - PROGRESS: at 19.68% examples, 438857 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:09:42,640 : INFO : EPOCH 1 - PROGRESS: at 29.54% examples, 439697 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:09:43,643 : INFO : EPOCH 1 - PROGRESS: at 39.54% examples, 442209 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:09:44,652 : INFO : EPOCH 1 - PROGRESS: at 48.80% examples, 437969 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:09:45,655 : INFO : EPOCH 1 - PROGRESS: at 58.68% examples, 438147 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:09:46,669 : INFO : EPOCH 1 - PROGRESS: at 68.53% examples, 437698 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:09:47,687 : INFO : EPOCH 1 - PROGRESS: at 78.57% examples, 436944 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:09:48,691 : INFO : EPOCH 1 - PROGRESS: at 87.93% examples, 435635 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:09:49,696 : INFO : EPOCH 1 - PROGRESS: at 97.47% examples, 434655 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:09:49,906 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-02-16 00:09:49,919 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-02-16 00:09:49,939 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-02-16 00:09:49,939 : INFO : EPOCH - 1 : training on 6022875 raw words (4500753 effective words) took 10.3s, 435100 effective words/s\n",
      "2023-02-16 00:09:50,957 : INFO : EPOCH 2 - PROGRESS: at 9.24% examples, 418089 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:09:51,973 : INFO : EPOCH 2 - PROGRESS: at 19.07% examples, 425208 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:09:52,974 : INFO : EPOCH 2 - PROGRESS: at 29.00% examples, 433814 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:09:54,002 : INFO : EPOCH 2 - PROGRESS: at 39.20% examples, 436952 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:09:55,004 : INFO : EPOCH 2 - PROGRESS: at 49.12% examples, 440130 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:09:56,024 : INFO : EPOCH 2 - PROGRESS: at 59.15% examples, 439865 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:09:57,028 : INFO : EPOCH 2 - PROGRESS: at 69.07% examples, 439756 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:09:58,030 : INFO : EPOCH 2 - PROGRESS: at 79.27% examples, 440581 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:09:59,056 : INFO : EPOCH 2 - PROGRESS: at 89.32% examples, 441138 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:10:00,058 : INFO : EPOCH 2 - PROGRESS: at 99.36% examples, 441918 words/s, in_qsize 4, out_qsize 0\n",
      "2023-02-16 00:10:00,095 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-02-16 00:10:00,103 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-02-16 00:10:00,108 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-02-16 00:10:00,108 : INFO : EPOCH - 2 : training on 6022875 raw words (4500394 effective words) took 10.2s, 442599 effective words/s\n",
      "2023-02-16 00:10:01,136 : INFO : EPOCH 3 - PROGRESS: at 9.78% examples, 435659 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:10:02,156 : INFO : EPOCH 3 - PROGRESS: at 20.02% examples, 443370 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:10:03,181 : INFO : EPOCH 3 - PROGRESS: at 30.21% examples, 445403 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:10:04,184 : INFO : EPOCH 3 - PROGRESS: at 40.23% examples, 446449 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:10:05,211 : INFO : EPOCH 3 - PROGRESS: at 50.24% examples, 447002 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:10:06,231 : INFO : EPOCH 3 - PROGRESS: at 60.58% examples, 448074 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:10:07,248 : INFO : EPOCH 3 - PROGRESS: at 71.10% examples, 448987 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:10:08,259 : INFO : EPOCH 3 - PROGRESS: at 81.27% examples, 448274 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:10:09,294 : INFO : EPOCH 3 - PROGRESS: at 91.32% examples, 448239 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:10:10,092 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-02-16 00:10:10,133 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-02-16 00:10:10,137 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-02-16 00:10:10,138 : INFO : EPOCH - 3 : training on 6022875 raw words (4500649 effective words) took 10.0s, 448786 effective words/s\n",
      "2023-02-16 00:10:11,164 : INFO : EPOCH 4 - PROGRESS: at 9.78% examples, 435832 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:10:12,203 : INFO : EPOCH 4 - PROGRESS: at 19.07% examples, 418631 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:10:13,215 : INFO : EPOCH 4 - PROGRESS: at 28.04% examples, 413594 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:10:14,222 : INFO : EPOCH 4 - PROGRESS: at 37.84% examples, 420263 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:10:15,244 : INFO : EPOCH 4 - PROGRESS: at 47.84% examples, 425130 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:10:16,267 : INFO : EPOCH 4 - PROGRESS: at 58.21% examples, 429558 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:10:17,272 : INFO : EPOCH 4 - PROGRESS: at 68.36% examples, 432847 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:10:18,288 : INFO : EPOCH 4 - PROGRESS: at 78.57% examples, 433748 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:10:19,311 : INFO : EPOCH 4 - PROGRESS: at 88.46% examples, 434407 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 00:10:20,330 : INFO : EPOCH 4 - PROGRESS: at 98.31% examples, 434413 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:10:20,439 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-02-16 00:10:20,480 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-02-16 00:10:20,485 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-02-16 00:10:20,485 : INFO : EPOCH - 4 : training on 6022875 raw words (4500473 effective words) took 10.3s, 434961 effective words/s\n",
      "2023-02-16 00:10:21,509 : INFO : EPOCH 5 - PROGRESS: at 9.78% examples, 438046 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:10:22,528 : INFO : EPOCH 5 - PROGRESS: at 20.02% examples, 445311 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:10:23,539 : INFO : EPOCH 5 - PROGRESS: at 30.06% examples, 446264 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:10:24,566 : INFO : EPOCH 5 - PROGRESS: at 40.23% examples, 446252 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:10:25,568 : INFO : EPOCH 5 - PROGRESS: at 50.06% examples, 447614 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:10:26,591 : INFO : EPOCH 5 - PROGRESS: at 60.12% examples, 445960 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:10:27,608 : INFO : EPOCH 5 - PROGRESS: at 70.57% examples, 447194 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:10:28,631 : INFO : EPOCH 5 - PROGRESS: at 81.10% examples, 447830 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:10:29,637 : INFO : EPOCH 5 - PROGRESS: at 90.87% examples, 447721 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:10:30,475 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-02-16 00:10:30,513 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-02-16 00:10:30,519 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-02-16 00:10:30,520 : INFO : EPOCH - 5 : training on 6022875 raw words (4501134 effective words) took 10.0s, 448686 effective words/s\n",
      "2023-02-16 00:10:30,520 : INFO : Word2Vec lifecycle event {'msg': 'training on 30114375 raw words (22503403 effective words) took 50.9s, 441846 effective words/s', 'datetime': '2023-02-16T00:10:30.520506', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2023-02-16 00:10:30,520 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=33359, vector_size=100, alpha=0.025)', 'datetime': '2023-02-16T00:10:30.520885', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "#text = [t.split() for t,p in train]\n",
    "text = [t.split() for t in train_df.text.map(preprocess)]\n",
    "\n",
    "# the following configuration is the default configuration\n",
    "w2v = gensim.models.word2vec.Word2Vec(sentences=text,\n",
    "                                vector_size=100, window=5,               ### here we train a cbow model \n",
    "                                min_count=5,                      \n",
    "                                sample=0.001, workers=3,\n",
    "                                sg=1, hs=0, negative=5,        ### set sg to 1 to train a sg model\n",
    "                                cbow_mean=1, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 00:10:30,523 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'W2v-movies.dat', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-02-16T00:10:30.523785', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}\n",
      "2023-02-16 00:10:30,524 : INFO : not storing attribute cum_table\n",
      "2023-02-16 00:10:30,546 : INFO : saved W2v-movies.dat\n"
     ]
    }
   ],
   "source": [
    "# Worth it to save the previous embedding\n",
    "w2v.save(\"W2v-movies.dat\")\n",
    "# You will be able to reload them:\n",
    "# w2v = gensim.models.Word2Vec.load(\"W2v-movies.dat\")\n",
    "# and you can continue the learning process if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: Test learnt embeddings\n",
    "\n",
    "The word embedding space directly encodes similarities between words: the vector coding for the word \"great\" will be closer to the vector coding for \"good\" than to the one coding for \"bad\". Generally, [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity) is the distance used when considering distance between vectors.\n",
    "\n",
    "KeyedVectors have a built in [similarity](https://radimrehurek.com/gensim/models /keyedvectors.html#gensim.models.keyedvectors.BaseKeyedVectors.similarity) method to compute the cosine similarity between words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great and good: 0.76782584\n",
      "great and bad: 0.5397215\n"
     ]
    }
   ],
   "source": [
    "# is great really closer to good than to bad ?\n",
    "print(\"great and good:\",w2v.wv.similarity(\"great\",\"good\"))\n",
    "print(\"great and bad:\",w2v.wv.similarity(\"great\",\"bad\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since cosine distance encodes similarity, neighboring words are supposed to be similar. The [most_similar](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.BaseKeyedVectors.most_similar) method returns the `topn` words given a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie :\n",
      "\t ('film', 0.9328461289405823)\n",
      "\t ('programme', 0.7791712284088135)\n",
      "\t ('flick', 0.7638271450996399)\n",
      "\t ('monstrosity', 0.7471099495887756)\n",
      "\t ('it', 0.7395325899124146)\n",
      "awesome :\n",
      "\t ('amazing', 0.7928280830383301)\n",
      "\t ('incredible', 0.7682960629463196)\n",
      "\t ('fantastic', 0.7515002489089966)\n",
      "\t ('cool', 0.7180612683296204)\n",
      "\t ('excellent', 0.7168706059455872)\n",
      "actor :\n",
      "\t ('musician', 0.736379861831665)\n",
      "\t ('actress', 0.7326823472976685)\n",
      "\t ('comedian', 0.7259320616722107)\n",
      "\t ('impersonation', 0.7138898968696594)\n",
      "\t ('songwriter', 0.689059853553772)\n"
     ]
    }
   ],
   "source": [
    "# The query can be as simple as a word, such as \"movie\"\n",
    "\n",
    "# Try changing the word\n",
    "for word in ['movie', 'awesome', 'actor']:\n",
    "    print(word, ':')\n",
    "    for item in w2v.wv.most_similar(word,topn=5):\n",
    "        print('\\t', item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it can be a more complicated query\n",
    "Word embedding spaces tend to encode much more.\n",
    "\n",
    "The most famous exemple is: `vec(king) - vec(man) + vec(woman) => vec(queen)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awesome bad -- good\n",
      "\t ('awful', 0.7341099977493286)\n",
      "\t ('Terrible', 0.6573300361633301)\n",
      "\t ('terrible', 0.6454448103904724)\n",
      "\t ('atrocious', 0.6421670913696289)\n",
      "\t ('horrible', 0.6358762979507446)\n",
      "actor woman -- man\n",
      "\t ('actress', 0.8530353307723999)\n",
      "\t ('comedienne', 0.6491321325302124)\n",
      "\t ('dancer', 0.6273465156555176)\n",
      "\t ('performer', 0.6254771947860718)\n",
      "\t ('gentleman', 0.6113918423652649)\n"
     ]
    }
   ],
   "source": [
    "# What is awesome - good + bad ?\n",
    "positives = [\n",
    "    [\"awesome\",\"bad\"],\n",
    "    [\"actor\",\"woman\"]\n",
    "]\n",
    "\n",
    "negatives = [\n",
    "    [\"good\"],\n",
    "    [\"man\"]\n",
    "]\n",
    "\n",
    "for i in range(2):\n",
    "    print(*positives[i], '--', *negatives[i])\n",
    "    for item in w2v.wv.most_similar(positive=positives[i],negative=negatives[i],topn=5):\n",
    "        print('\\t', item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie movies -- film\n",
      "\t ('flicks', 0.7785832285881042)\n",
      "\t ('films', 0.7654721140861511)\n",
      "\t ('cartoons', 0.7107298374176025)\n",
      "\t ('slashers', 0.6972025632858276)\n",
      "\t ('comedies', 0.6872580051422119)\n",
      "actor actors -- actress\n",
      "\t ('Spacey', 0.6671654582023621)\n",
      "\t ('professionals', 0.634136974811554)\n",
      "\t ('scriptwriters', 0.6328943967819214)\n",
      "\t ('amateurs', 0.6313664317131042)\n",
      "\t ('directors', 0.6313294768333435)\n"
     ]
    }
   ],
   "source": [
    "        \n",
    "#w2v.wv.most_similar(positive=[\"awesome\",\"bad\"],negative=[\"good\"],topn=3)  \n",
    "\n",
    "#w2v.wv.most_similar(positive=[\"actor\",\"woman\"],negative=[\"man\"],topn=3) # do the famous exemple works for actor ?\n",
    "\n",
    "\n",
    "# Try other things like plurals for exemple.\n",
    "positives = [\n",
    "    [\"movie\",\"movies\"],\n",
    "    [\"actor\",\"actors\"]\n",
    "]\n",
    "\n",
    "negatives = [\n",
    "    [\"film\"],\n",
    "    [\"actress\"]\n",
    "]\n",
    "\n",
    "for i in range(2):\n",
    "    print(*positives[i], '--', *negatives[i])\n",
    "    for item in w2v.wv.most_similar(positive=positives[i],negative=negatives[i],topn=5):\n",
    "        print('\\t', item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test learnt \"synctactic\" and \"semantic\" similarities, Mikolov et al. introduced a special dataset containing a wide variety of three way similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out = w2v.wv.evaluate_word_analogies(\"ressources/questions-words.txt\",case_insensitive=True)  #original semantic syntactic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When training the w2v models on the review dataset, since it hasn't been learnt with a lot of data, it does not perform very well.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: Loading a pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Gensim, embeddings are loaded and can be used via the [\"KeyedVectors\"](https://radimrehurek.com/gensim/models/keyedvectors.html) class\n",
    "\n",
    "> Since trained word vectors are independent from the way they were trained (Word2Vec, FastText, WordRank, VarEmbed etc), they can be represented by a standalone structure, as implemented in this module.\n",
    "\n",
    ">The structure is called “KeyedVectors” and is essentially a mapping between entities and vectors. Each entity is identified by its string id, so this is a mapping between {str => 1D numpy array}.\n",
    "\n",
    ">The entity typically corresponds to a word (so the mapping maps words to 1D vectors), but for some models, they key can also correspond to a document, a graph node etc. To generalize over different use-cases, this module calls the keys entities. Each entity is always represented by its string id, no matter whether the entity is a word, a document or a graph node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 00:10:30,590 : INFO : loading KeyedVectors object from word2vec-google-news-300.dat\n",
      "2023-02-16 00:10:31,509 : INFO : loading vectors from word2vec-google-news-300.dat.vectors.npy with mmap=None\n",
      "2023-02-16 00:10:33,297 : INFO : KeyedVectors lifecycle event {'fname': 'word2vec-google-news-300.dat', 'datetime': '2023-02-16T00:10:33.282893', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "#from gensim.test.utils import get_tmpfile\n",
    "import gensim.downloader as api\n",
    "bload = True\n",
    "fname = \"word2vec-google-news-300\"\n",
    "sdir = \"\" # Change\n",
    "\n",
    "if(bload==True):\n",
    "    wv_pre_trained = gensim.models.KeyedVectors.load(sdir+fname+\".dat\")\n",
    "else:    \n",
    "    wv_pre_trained = api.load(fname)\n",
    "    wv_pre_trained.save(sdir+fname+\".dat\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform the \"synctactic\" and \"semantic\" evaluations again. Conclude on the pre-trained embeddings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great and good: 0.72915095\n",
      "great and bad: 0.3928765\n"
     ]
    }
   ],
   "source": [
    "print(\"great and good:\",wv_pre_trained.similarity(\"great\",\"good\"))\n",
    "print(\"great and bad:\",wv_pre_trained.similarity(\"great\",\"bad\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie :\n",
      "\t ('film', 0.8676770329475403)\n",
      "\t ('movies', 0.8013108372688293)\n",
      "\t ('films', 0.7363012433052063)\n",
      "\t ('moive', 0.6830361485481262)\n",
      "\t ('Movie', 0.6693679094314575)\n",
      "awesome :\n",
      "\t ('amazing', 0.8282864689826965)\n",
      "\t ('unbelievable', 0.7464959025382996)\n",
      "\t ('fantastic', 0.7453292012214661)\n",
      "\t ('incredible', 0.7390913963317871)\n",
      "\t ('unbelieveable', 0.6678116917610168)\n",
      "actor :\n",
      "\t ('actress', 0.7930010557174683)\n",
      "\t ('Actor', 0.7446157932281494)\n",
      "\t ('thesp', 0.6954971551895142)\n",
      "\t ('thespian', 0.6651668548583984)\n",
      "\t ('actors', 0.6519852876663208)\n"
     ]
    }
   ],
   "source": [
    "for word in ['movie', 'awesome', 'actor']:\n",
    "    print(word, ':')\n",
    "    for item in wv_pre_trained.most_similar(word,topn=5):\n",
    "        print('\\t', item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awesome bad -- good\n",
      "\t ('horrible', 0.5953484773635864)\n",
      "\t ('amazing', 0.5928210020065308)\n",
      "\t ('weird', 0.5782380700111389)\n",
      "\t ('freaky', 0.5767403244972229)\n",
      "\t ('unbelievable', 0.5747914910316467)\n",
      "actor woman -- man\n",
      "\t ('actress', 0.8602624535560608)\n",
      "\t ('actresses', 0.6596671342849731)\n",
      "\t ('thesp', 0.6290916800498962)\n",
      "\t ('Actress', 0.6165293455123901)\n",
      "\t ('actress_Rachel_Weisz', 0.5997323393821716)\n"
     ]
    }
   ],
   "source": [
    "positives = [\n",
    "    [\"awesome\",\"bad\"],\n",
    "    [\"actor\",\"woman\"]\n",
    "]\n",
    "\n",
    "negatives = [\n",
    "    [\"good\"],\n",
    "    [\"man\"]\n",
    "]\n",
    "\n",
    "for i in range(2):\n",
    "    print(*positives[i], '--', *negatives[i])\n",
    "    for item in wv_pre_trained.most_similar(positive=positives[i],negative=negatives[i],topn=5):\n",
    "        print('\\t', item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie movies -- film\n",
      "\t ('films', 0.6389263868331909)\n",
      "\t ('Movies', 0.6188486814498901)\n",
      "\t ('flicks', 0.6120561361312866)\n",
      "\t ('Hollywood_blockbusters', 0.5958892703056335)\n",
      "\t ('romcoms', 0.5864962339401245)\n",
      "actor actors -- actress\n",
      "\t ('Actors', 0.6128960251808167)\n",
      "\t ('thesps', 0.5747196674346924)\n",
      "\t ('screenwriters', 0.5588046908378601)\n",
      "\t ('thespians', 0.5531652569770813)\n",
      "\t ('thespian', 0.5476460456848145)\n"
     ]
    }
   ],
   "source": [
    "positives = [\n",
    "    [\"movie\",\"movies\"],\n",
    "    [\"actor\",\"actors\"]\n",
    "]\n",
    "\n",
    "negatives = [\n",
    "    [\"film\"],\n",
    "    [\"actress\"]\n",
    "]\n",
    "\n",
    "for i in range(2):\n",
    "    print(*positives[i], '--', *negatives[i])\n",
    "    for item in wv_pre_trained.most_similar(positive=positives[i],negative=negatives[i],topn=5):\n",
    "        print('\\t', item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4:  sentiment classification\n",
    "\n",
    "In the previous practical session, we used a bag of word approach to transform text into vectors.\n",
    "Here, we propose to try to use word vectors (previously learnt or loaded).\n",
    "\n",
    "\n",
    "### <font color='green'> Since we have only word vectors and that sentences are made of multiple words, we need to aggregate them. </font>\n",
    "\n",
    "\n",
    "### (1) Vectorize reviews using word vectors:\n",
    "\n",
    "Word aggregation can be done in different ways:\n",
    "\n",
    "- Sum\n",
    "- Average\n",
    "- Min/feature\n",
    "- Max/feature\n",
    "\n",
    "#### a few pointers:\n",
    "\n",
    "- `w2v.wv.vocab` is a `set()` of the vocabulary (all existing words in your model)\n",
    "- `np.minimum(a,b) and np.maximum(a,b)` respectively return element-wise min/max "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# We first need to vectorize text:\n",
    "# First we propose to a sum of them\n",
    "\n",
    "\n",
    "def vectorize(text, f=np.sum, model=wv_pre_trained):\n",
    "    \"\"\"\n",
    "    This function should vectorize one review\n",
    "\n",
    "    input: str, numpy agregate function\n",
    "    output: np.array(float)\n",
    "    \"\"\"    \n",
    "    vec = []\n",
    "    for word in preprocess(text):\n",
    "        if word in model.key_to_index:\n",
    "            vec.append(model[word])\n",
    "    return f(vec, axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.8882080e+01,  5.0358612e+01, -4.2053223e-02,  5.2835480e+01,\n",
       "       -2.5050629e+01,  1.0630341e+01, -3.9978210e+01, -2.2337036e+01,\n",
       "       -1.9577698e+01,  1.1810776e+01, -1.8968021e+01, -3.8820648e+01,\n",
       "       -8.7164398e+01,  1.1624546e+01, -5.5066895e+01,  3.9756592e+01,\n",
       "        4.4158363e+01,  7.1197632e+01, -4.0677338e+00,  1.3945007e-01,\n",
       "       -1.0449817e+02, -1.5634384e+01,  4.9755814e+01,  8.5149994e+00,\n",
       "       -3.4336380e+01,  1.0841086e+01, -1.0523462e+02,  2.0532532e+01,\n",
       "       -1.1974487e+01, -8.8734436e+00, -3.5450745e+00,  1.3266159e+01,\n",
       "       -2.8181610e+01, -4.5545288e+01, -5.4851898e+01,  3.7212555e+01,\n",
       "       -8.4447968e+01,  5.0229980e+01, -2.4678310e+01,  3.7364990e+01,\n",
       "       -1.5668884e+01, -1.7890625e+01,  2.4233398e+01,  3.5927063e+01,\n",
       "        2.1099434e+01, -1.5949348e+01, -1.3954895e+01, -7.5196045e+01,\n",
       "       -5.0344238e+01,  3.2897095e+01, -7.5712280e+01,  1.0140381e+02,\n",
       "       -1.0659912e+01,  9.3589050e+01,  1.5606079e+01,  5.3395996e+01,\n",
       "       -6.4790283e+01, -3.9895462e+01,  5.2529144e-01, -6.5427002e+01,\n",
       "       -5.7098602e+01, -3.1768066e+01, -7.9039368e+01, -2.2490005e+01,\n",
       "       -1.5918243e+01, -8.0413818e+01, -4.6038422e+01,  5.0751221e+01,\n",
       "       -2.3664978e+01,  1.9953957e+01,  1.4124756e+01, -2.8575134e+01,\n",
       "        1.5653076e+01, -6.7405701e+00, -1.6188969e+01, -5.6878662e+00,\n",
       "        5.4065063e+01,  9.7600403e+00,  7.3929138e+00, -3.7852661e+01,\n",
       "       -6.1154419e+01, -2.4195724e+00, -1.4335476e+01, -4.2929688e+00,\n",
       "        4.8793945e+01,  2.8302124e+01, -8.9952393e+00,  9.5622803e+01,\n",
       "        7.7807465e+00,  2.9292519e+01,  1.1280594e+01,  1.0579102e+01,\n",
       "       -1.3919189e+01, -5.2255127e+01,  1.6975586e+01,  4.3367142e+01,\n",
       "       -3.5861206e+01,  4.3778748e+01,  1.0290137e+02, -1.1065529e+01,\n",
       "       -3.3869995e+01,  1.8422241e+00, -2.4602173e+01, -6.5405273e+00,\n",
       "       -2.6351379e+01,  5.6049652e+01, -3.2651001e+01,  1.7404846e+01,\n",
       "       -4.7469482e+00,  9.4433289e+00, -5.9560181e+01, -7.3665436e+01,\n",
       "       -1.3284355e+01, -1.5439667e+01,  2.7445862e+01,  6.4594604e+01,\n",
       "        3.2912125e+01, -1.4444019e+01, -1.2857986e+01, -1.7324921e+01,\n",
       "        4.9555664e+01,  2.8339355e+01, -3.1159058e+00,  8.0742188e+00,\n",
       "        4.5458496e+01, -6.6907349e+01, -4.2538849e+01, -7.2573242e+00,\n",
       "        2.2798130e+01,  4.5603500e+01, -3.1644226e+01, -1.1277710e+01,\n",
       "       -2.9940155e+01, -1.8795105e+01, -6.9766258e+01,  3.1901947e+01,\n",
       "       -1.7119873e+01,  1.4970703e+01,  9.7975830e+01,  5.7806213e+01,\n",
       "        8.0631714e+01, -2.9862011e+01,  2.1298950e+01, -1.9485352e+01,\n",
       "       -2.4480835e+01, -3.8301254e+01, -2.9290527e+01,  6.4237549e+01,\n",
       "       -2.4418945e+01,  1.3951523e+01,  2.8418823e+01, -1.2114172e+02,\n",
       "       -2.1752487e+01, -1.7212219e+01, -4.2718124e+01, -3.2562012e+01,\n",
       "        3.2953674e+01,  7.2873535e+01, -9.8032684e+00, -1.5802277e+01,\n",
       "        6.7636108e+00,  3.7984619e+01, -2.1875000e+00,  1.9942017e+00,\n",
       "       -4.5611267e+00, -2.0503738e+01,  6.7586670e+01,  1.4614243e+01,\n",
       "       -4.2497093e+01,  3.3869202e+01, -4.3817200e+01, -3.9695068e+01,\n",
       "       -1.4638092e+01, -3.1286011e+01, -6.2565231e+00,  9.3530029e+01,\n",
       "        1.0566431e+02, -8.4190430e+01,  1.1244690e+01, -3.5478775e+01,\n",
       "        2.1457214e+00,  1.1929943e+01,  1.6400856e+01, -2.2264404e+01,\n",
       "       -1.0637787e+01,  3.4596161e+01, -1.8946533e+01,  2.6924301e+01,\n",
       "       -1.3759827e+01,  1.6108643e+01,  4.5768860e+01, -1.7854370e+01,\n",
       "       -1.0060608e+02, -4.9949951e+00,  5.1762207e+01,  1.9117310e+01,\n",
       "       -2.7926331e+01, -5.1379395e+00,  2.6325165e+01, -3.7694702e+01,\n",
       "       -4.2099182e+01,  1.0446167e+01, -8.2152222e+01, -5.4556892e+01,\n",
       "        2.6914307e+01, -3.0969955e+01, -1.2377319e+01,  4.1156982e+01,\n",
       "       -1.5810959e+01,  6.5528687e+01,  6.1385803e+01,  3.2758575e+01,\n",
       "       -5.8956329e+01,  6.8284607e-01, -3.4483032e+01,  1.2551792e+01,\n",
       "        6.3923828e+01, -3.0488861e+01, -6.3625000e+01,  9.5935059e-01,\n",
       "       -5.0934174e+01,  5.7905212e+01,  2.6764160e+01, -6.3581848e+00,\n",
       "        2.2050781e+00, -3.2548706e+01,  3.1356567e+01,  2.3768188e+01,\n",
       "        1.3167763e+00, -5.4689301e+01,  1.2605499e+01, -2.0819542e+01,\n",
       "       -3.8497643e+01,  3.1405029e+00,  4.1885986e+00,  8.0888443e+00,\n",
       "        1.9158264e+01,  3.8356445e+01,  4.0995514e+01,  4.0217468e+01,\n",
       "        3.7469086e+01,  3.5427490e+01,  1.1444043e+02, -2.1804565e+01,\n",
       "       -8.6026077e+00,  3.4682098e+01, -6.4529358e+01,  6.3497192e+01,\n",
       "        1.4808777e+01, -2.8199799e+01,  3.0207558e+01,  1.2726807e+01,\n",
       "        2.5735046e+01,  4.2998413e+01, -4.6005859e+00, -5.2063751e+01,\n",
       "       -2.2273376e+01,  2.5625488e+01,  1.2070847e+01, -3.5146606e+01,\n",
       "        2.9009399e+01, -5.6553001e+00,  4.2107315e+01, -8.1582947e+00,\n",
       "       -3.6981026e+01,  1.0448608e+01, -5.0372314e-01,  6.1401367e+00,\n",
       "       -3.6754761e+00, -2.1451599e+01, -3.1900040e+01, -6.6785889e+00,\n",
       "        1.6368774e+01,  1.3072327e+01,  3.1112976e+01, -3.2759705e+01,\n",
       "       -7.0961731e+01, -5.7105713e+01, -4.1383118e+01,  2.8545044e+01,\n",
       "       -4.0392456e+01,  5.9244087e+01,  1.6551819e+00,  3.8143921e-01,\n",
       "        3.1848907e+00,  2.7456787e+01, -3.8246155e+00, -5.9337158e+00,\n",
       "       -2.2854858e+01, -1.3662170e+01,  3.0015858e+01, -9.9426270e-01,\n",
       "       -3.7488022e+01,  3.8440002e+01, -1.1009079e+01, -6.2782959e+01,\n",
       "       -4.2790405e+01, -1.1065491e+01, -4.8208313e+01,  5.7849976e+01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize(train_df.text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.8882080e+01  5.0358612e+01 -4.2053223e-02  5.2835480e+01\n",
      " -2.5050629e+01  1.0630341e+01 -3.9978210e+01 -2.2337036e+01\n",
      " -1.9577698e+01  1.1810776e+01 -1.8968021e+01 -3.8820648e+01\n",
      " -8.7164398e+01  1.1624546e+01 -5.5066895e+01  3.9756592e+01\n",
      "  4.4158363e+01  7.1197632e+01 -4.0677338e+00  1.3945007e-01\n",
      " -1.0449817e+02 -1.5634384e+01  4.9755814e+01  8.5149994e+00\n",
      " -3.4336380e+01  1.0841086e+01 -1.0523462e+02  2.0532532e+01\n",
      " -1.1974487e+01 -8.8734436e+00 -3.5450745e+00  1.3266159e+01\n",
      " -2.8181610e+01 -4.5545288e+01 -5.4851898e+01  3.7212555e+01\n",
      " -8.4447968e+01  5.0229980e+01 -2.4678310e+01  3.7364990e+01\n",
      " -1.5668884e+01 -1.7890625e+01  2.4233398e+01  3.5927063e+01\n",
      "  2.1099434e+01 -1.5949348e+01 -1.3954895e+01 -7.5196045e+01\n",
      " -5.0344238e+01  3.2897095e+01 -7.5712280e+01  1.0140381e+02\n",
      " -1.0659912e+01  9.3589050e+01  1.5606079e+01  5.3395996e+01\n",
      " -6.4790283e+01 -3.9895462e+01  5.2529144e-01 -6.5427002e+01\n",
      " -5.7098602e+01 -3.1768066e+01 -7.9039368e+01 -2.2490005e+01\n",
      " -1.5918243e+01 -8.0413818e+01 -4.6038422e+01  5.0751221e+01\n",
      " -2.3664978e+01  1.9953957e+01  1.4124756e+01 -2.8575134e+01\n",
      "  1.5653076e+01 -6.7405701e+00 -1.6188969e+01 -5.6878662e+00\n",
      "  5.4065063e+01  9.7600403e+00  7.3929138e+00 -3.7852661e+01\n",
      " -6.1154419e+01 -2.4195724e+00 -1.4335476e+01 -4.2929688e+00\n",
      "  4.8793945e+01  2.8302124e+01 -8.9952393e+00  9.5622803e+01\n",
      "  7.7807465e+00  2.9292519e+01  1.1280594e+01  1.0579102e+01\n",
      " -1.3919189e+01 -5.2255127e+01  1.6975586e+01  4.3367142e+01\n",
      " -3.5861206e+01  4.3778748e+01  1.0290137e+02 -1.1065529e+01\n",
      " -3.3869995e+01  1.8422241e+00 -2.4602173e+01 -6.5405273e+00\n",
      " -2.6351379e+01  5.6049652e+01 -3.2651001e+01  1.7404846e+01\n",
      " -4.7469482e+00  9.4433289e+00 -5.9560181e+01 -7.3665436e+01\n",
      " -1.3284355e+01 -1.5439667e+01  2.7445862e+01  6.4594604e+01\n",
      "  3.2912125e+01 -1.4444019e+01 -1.2857986e+01 -1.7324921e+01\n",
      "  4.9555664e+01  2.8339355e+01 -3.1159058e+00  8.0742188e+00\n",
      "  4.5458496e+01 -6.6907349e+01 -4.2538849e+01 -7.2573242e+00\n",
      "  2.2798130e+01  4.5603500e+01 -3.1644226e+01 -1.1277710e+01\n",
      " -2.9940155e+01 -1.8795105e+01 -6.9766258e+01  3.1901947e+01\n",
      " -1.7119873e+01  1.4970703e+01  9.7975830e+01  5.7806213e+01\n",
      "  8.0631714e+01 -2.9862011e+01  2.1298950e+01 -1.9485352e+01\n",
      " -2.4480835e+01 -3.8301254e+01 -2.9290527e+01  6.4237549e+01\n",
      " -2.4418945e+01  1.3951523e+01  2.8418823e+01 -1.2114172e+02\n",
      " -2.1752487e+01 -1.7212219e+01 -4.2718124e+01 -3.2562012e+01\n",
      "  3.2953674e+01  7.2873535e+01 -9.8032684e+00 -1.5802277e+01\n",
      "  6.7636108e+00  3.7984619e+01 -2.1875000e+00  1.9942017e+00\n",
      " -4.5611267e+00 -2.0503738e+01  6.7586670e+01  1.4614243e+01\n",
      " -4.2497093e+01  3.3869202e+01 -4.3817200e+01 -3.9695068e+01\n",
      " -1.4638092e+01 -3.1286011e+01 -6.2565231e+00  9.3530029e+01\n",
      "  1.0566431e+02 -8.4190430e+01  1.1244690e+01 -3.5478775e+01\n",
      "  2.1457214e+00  1.1929943e+01  1.6400856e+01 -2.2264404e+01\n",
      " -1.0637787e+01  3.4596161e+01 -1.8946533e+01  2.6924301e+01\n",
      " -1.3759827e+01  1.6108643e+01  4.5768860e+01 -1.7854370e+01\n",
      " -1.0060608e+02 -4.9949951e+00  5.1762207e+01  1.9117310e+01\n",
      " -2.7926331e+01 -5.1379395e+00  2.6325165e+01 -3.7694702e+01\n",
      " -4.2099182e+01  1.0446167e+01 -8.2152222e+01 -5.4556892e+01\n",
      "  2.6914307e+01 -3.0969955e+01 -1.2377319e+01  4.1156982e+01\n",
      " -1.5810959e+01  6.5528687e+01  6.1385803e+01  3.2758575e+01\n",
      " -5.8956329e+01  6.8284607e-01 -3.4483032e+01  1.2551792e+01\n",
      "  6.3923828e+01 -3.0488861e+01 -6.3625000e+01  9.5935059e-01\n",
      " -5.0934174e+01  5.7905212e+01  2.6764160e+01 -6.3581848e+00\n",
      "  2.2050781e+00 -3.2548706e+01  3.1356567e+01  2.3768188e+01\n",
      "  1.3167763e+00 -5.4689301e+01  1.2605499e+01 -2.0819542e+01\n",
      " -3.8497643e+01  3.1405029e+00  4.1885986e+00  8.0888443e+00\n",
      "  1.9158264e+01  3.8356445e+01  4.0995514e+01  4.0217468e+01\n",
      "  3.7469086e+01  3.5427490e+01  1.1444043e+02 -2.1804565e+01\n",
      " -8.6026077e+00  3.4682098e+01 -6.4529358e+01  6.3497192e+01\n",
      "  1.4808777e+01 -2.8199799e+01  3.0207558e+01  1.2726807e+01\n",
      "  2.5735046e+01  4.2998413e+01 -4.6005859e+00 -5.2063751e+01\n",
      " -2.2273376e+01  2.5625488e+01  1.2070847e+01 -3.5146606e+01\n",
      "  2.9009399e+01 -5.6553001e+00  4.2107315e+01 -8.1582947e+00\n",
      " -3.6981026e+01  1.0448608e+01 -5.0372314e-01  6.1401367e+00\n",
      " -3.6754761e+00 -2.1451599e+01 -3.1900040e+01 -6.6785889e+00\n",
      "  1.6368774e+01  1.3072327e+01  3.1112976e+01 -3.2759705e+01\n",
      " -7.0961731e+01 -5.7105713e+01 -4.1383118e+01  2.8545044e+01\n",
      " -4.0392456e+01  5.9244087e+01  1.6551819e+00  3.8143921e-01\n",
      "  3.1848907e+00  2.7456787e+01 -3.8246155e+00 -5.9337158e+00\n",
      " -2.2854858e+01 -1.3662170e+01  3.0015858e+01 -9.9426270e-01\n",
      " -3.7488022e+01  3.8440002e+01 -1.1009079e+01 -6.2782959e+01\n",
      " -4.2790405e+01 -1.1065491e+01 -4.8208313e+01  5.7849976e+01]\n"
     ]
    }
   ],
   "source": [
    "#X = [vectorize(text) for text,pol in train]\n",
    "X = list(train_df.text.map(vectorize))\n",
    "y = np.array(train_df.label)\n",
    "\n",
    "#X_test = [vectorize(text) for text,pol in test]\n",
    "X_test = list(test_df.text.map(vectorize))\n",
    "y_test = np.array(test_df.label)\n",
    "\n",
    "#let's see what a review vector looks like.\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Train a classifier \n",
    "as in the previous practical session, train a logistic regression to do sentiment classification with word vectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.62832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benkabongo25/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Scikit Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X, y)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print('Accuracy :', accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_train_test(f, m=wv_pre_trained):\n",
    "    l = lambda x: vectorize(x, f, m)\n",
    "    \n",
    "    #X = [vectorize(text) for text,pol in train]\n",
    "    X = list(train_df.text.map(l))\n",
    "    y = np.array(train_df.label)\n",
    "\n",
    "    #X_test = [vectorize(text) for text,pol in test]\n",
    "    X_test = list(test_df.text.map(l))\n",
    "    y_test = np.array(test_df.label)\n",
    "    \n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X, y)\n",
    "\n",
    "    y_pred = lr.predict(X_test)\n",
    "\n",
    "    return accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6118"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_train_test(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benkabongo25/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5644"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_train_test(np.min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "performance should be worst than with bag of word (~80%). Sum/Mean aggregation does not work well on long reviews (especially with many frequent words). This adds a lot of noise.\n",
    "\n",
    "## **Todo** :  Try answering the following questions:\n",
    "\n",
    "- Which word2vec model works best: skip-gram or cbow\n",
    "- Do pretrained vectors work best than those learnt on the train dataset ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 00:14:22,383 : INFO : collecting all words and their counts\n",
      "2023-02-16 00:14:22,385 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-02-16 00:14:22,895 : INFO : PROGRESS: at sentence #10000, processed 2426102 words, keeping 61702 word types\n",
      "2023-02-16 00:14:23,464 : INFO : PROGRESS: at sentence #20000, processed 4816878 words, keeping 84298 word types\n",
      "2023-02-16 00:14:23,721 : INFO : collected 93201 word types from a corpus of 6022875 raw words and 25000 sentences\n",
      "2023-02-16 00:14:23,722 : INFO : Creating a fresh vocabulary\n",
      "2023-02-16 00:14:23,815 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 33359 unique words (35.79253441486679%% of original 93201, drops 59842)', 'datetime': '2023-02-16T00:14:23.815879', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2023-02-16 00:14:23,816 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 5924674 word corpus (98.36953282277982%% of original 6022875, drops 98201)', 'datetime': '2023-02-16T00:14:23.816319', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2023-02-16 00:14:23,931 : INFO : deleting the raw counts dictionary of 93201 items\n",
      "2023-02-16 00:14:23,932 : INFO : sample=0.001 downsamples 47 most-common words\n",
      "2023-02-16 00:14:23,932 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 4500851.640108086 word corpus (76.0%% of prior 5924674)', 'datetime': '2023-02-16T00:14:23.932860', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2023-02-16 00:14:24,158 : INFO : estimated required memory for 33359 words and 100 dimensions: 43366700 bytes\n",
      "2023-02-16 00:14:24,160 : INFO : resetting layer weights\n",
      "2023-02-16 00:14:24,175 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-02-16T00:14:24.175174', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2023-02-16 00:14:24,175 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 33359 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-02-16T00:14:24.175669', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2023-02-16 00:14:25,197 : INFO : EPOCH 1 - PROGRESS: at 9.78% examples, 438430 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:14:26,207 : INFO : EPOCH 1 - PROGRESS: at 20.02% examples, 447068 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:14:27,218 : INFO : EPOCH 1 - PROGRESS: at 30.21% examples, 449841 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:14:28,231 : INFO : EPOCH 1 - PROGRESS: at 40.38% examples, 450555 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:14:29,249 : INFO : EPOCH 1 - PROGRESS: at 50.42% examples, 451160 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:14:30,265 : INFO : EPOCH 1 - PROGRESS: at 60.72% examples, 451714 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:14:31,286 : INFO : EPOCH 1 - PROGRESS: at 71.30% examples, 451935 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:14:32,302 : INFO : EPOCH 1 - PROGRESS: at 81.78% examples, 452403 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:14:33,330 : INFO : EPOCH 1 - PROGRESS: at 91.82% examples, 452245 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:14:34,076 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-02-16 00:14:34,108 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-02-16 00:14:34,113 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-02-16 00:14:34,114 : INFO : EPOCH - 1 : training on 6022875 raw words (4500700 effective words) took 9.9s, 452946 effective words/s\n",
      "2023-02-16 00:14:35,134 : INFO : EPOCH 2 - PROGRESS: at 9.78% examples, 439601 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:14:36,146 : INFO : EPOCH 2 - PROGRESS: at 20.02% examples, 447239 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:14:37,168 : INFO : EPOCH 2 - PROGRESS: at 30.21% examples, 448382 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:14:38,175 : INFO : EPOCH 2 - PROGRESS: at 40.38% examples, 450064 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:14:39,198 : INFO : EPOCH 2 - PROGRESS: at 50.42% examples, 450426 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:14:40,220 : INFO : EPOCH 2 - PROGRESS: at 60.72% examples, 450677 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:14:41,243 : INFO : EPOCH 2 - PROGRESS: at 71.30% examples, 450963 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:14:42,255 : INFO : EPOCH 2 - PROGRESS: at 81.78% examples, 451773 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:14:43,280 : INFO : EPOCH 2 - PROGRESS: at 91.82% examples, 451846 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:14:44,016 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-02-16 00:14:44,055 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-02-16 00:14:44,060 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-02-16 00:14:44,060 : INFO : EPOCH - 2 : training on 6022875 raw words (4501270 effective words) took 9.9s, 452698 effective words/s\n",
      "2023-02-16 00:14:45,079 : INFO : EPOCH 3 - PROGRESS: at 9.78% examples, 439644 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:14:46,086 : INFO : EPOCH 3 - PROGRESS: at 20.02% examples, 448491 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:14:47,098 : INFO : EPOCH 3 - PROGRESS: at 30.21% examples, 450652 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:14:48,102 : INFO : EPOCH 3 - PROGRESS: at 40.38% examples, 452125 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:14:49,118 : INFO : EPOCH 3 - PROGRESS: at 50.42% examples, 452485 words/s, in_qsize 6, out_qsize 0\n",
      "2023-02-16 00:14:50,136 : INFO : EPOCH 3 - PROGRESS: at 60.72% examples, 452746 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:14:51,143 : INFO : EPOCH 3 - PROGRESS: at 71.10% examples, 452636 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:14:52,161 : INFO : EPOCH 3 - PROGRESS: at 81.63% examples, 452862 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:14:53,164 : INFO : EPOCH 3 - PROGRESS: at 91.32% examples, 452234 words/s, in_qsize 6, out_qsize 0\n",
      "2023-02-16 00:14:53,965 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-02-16 00:14:54,004 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-02-16 00:14:54,009 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-02-16 00:14:54,009 : INFO : EPOCH - 3 : training on 6022875 raw words (4500313 effective words) took 9.9s, 452365 effective words/s\n",
      "2023-02-16 00:14:55,026 : INFO : EPOCH 4 - PROGRESS: at 9.78% examples, 440981 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:14:56,037 : INFO : EPOCH 4 - PROGRESS: at 20.02% examples, 448144 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:14:57,050 : INFO : EPOCH 4 - PROGRESS: at 30.21% examples, 450185 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:14:58,057 : INFO : EPOCH 4 - PROGRESS: at 40.38% examples, 451481 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:14:59,076 : INFO : EPOCH 4 - PROGRESS: at 50.42% examples, 451810 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:15:00,095 : INFO : EPOCH 4 - PROGRESS: at 60.72% examples, 452061 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:15:01,113 : INFO : EPOCH 4 - PROGRESS: at 71.30% examples, 452412 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:15:02,132 : INFO : EPOCH 4 - PROGRESS: at 81.78% examples, 452601 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:15:03,162 : INFO : EPOCH 4 - PROGRESS: at 91.82% examples, 452383 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:15:03,906 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-02-16 00:15:03,944 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-02-16 00:15:03,950 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 00:15:03,950 : INFO : EPOCH - 4 : training on 6022875 raw words (4500226 effective words) took 9.9s, 452823 effective words/s\n",
      "2023-02-16 00:15:04,952 : INFO : EPOCH 5 - PROGRESS: at 9.24% examples, 425093 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:15:05,964 : INFO : EPOCH 5 - PROGRESS: at 19.53% examples, 440294 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:15:06,964 : INFO : EPOCH 5 - PROGRESS: at 28.83% examples, 434708 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:15:07,966 : INFO : EPOCH 5 - PROGRESS: at 38.48% examples, 434881 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:15:08,968 : INFO : EPOCH 5 - PROGRESS: at 48.30% examples, 437066 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:15:09,992 : INFO : EPOCH 5 - PROGRESS: at 58.68% examples, 439585 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:15:11,015 : INFO : EPOCH 5 - PROGRESS: at 69.07% examples, 441439 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:15:12,043 : INFO : EPOCH 5 - PROGRESS: at 79.62% examples, 442499 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:15:13,070 : INFO : EPOCH 5 - PROGRESS: at 89.80% examples, 443586 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:15:14,046 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-02-16 00:15:14,061 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-02-16 00:15:14,067 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-02-16 00:15:14,067 : INFO : EPOCH - 5 : training on 6022875 raw words (4501806 effective words) took 10.1s, 444995 effective words/s\n",
      "2023-02-16 00:15:14,068 : INFO : Word2Vec lifecycle event {'msg': 'training on 30114375 raw words (22504315 effective words) took 49.9s, 451041 effective words/s', 'datetime': '2023-02-16T00:15:14.067964', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2023-02-16 00:15:14,068 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=33359, vector_size=100, alpha=0.025)', 'datetime': '2023-02-16T00:15:14.068303', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "w2v_sg = gensim.models.word2vec.Word2Vec(sentences=text,\n",
    "                                vector_size=100, window=5,               ### here we train a cbow model \n",
    "                                min_count=5,                      \n",
    "                                sample=0.001, workers=3,\n",
    "                                sg=1, hs=0, negative=5,        ### set sg to 1 to train a sg model\n",
    "                                cbow_mean=1, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 00:15:14,074 : INFO : collecting all words and their counts\n",
      "2023-02-16 00:15:14,074 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-02-16 00:15:14,339 : INFO : PROGRESS: at sentence #10000, processed 2426102 words, keeping 61702 word types\n",
      "2023-02-16 00:15:14,600 : INFO : PROGRESS: at sentence #20000, processed 4816878 words, keeping 84298 word types\n",
      "2023-02-16 00:15:14,736 : INFO : collected 93201 word types from a corpus of 6022875 raw words and 25000 sentences\n",
      "2023-02-16 00:15:14,737 : INFO : Creating a fresh vocabulary\n",
      "2023-02-16 00:15:14,823 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 33359 unique words (35.79253441486679%% of original 93201, drops 59842)', 'datetime': '2023-02-16T00:15:14.823505', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2023-02-16 00:15:14,823 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 5924674 word corpus (98.36953282277982%% of original 6022875, drops 98201)', 'datetime': '2023-02-16T00:15:14.823885', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2023-02-16 00:15:14,939 : INFO : deleting the raw counts dictionary of 93201 items\n",
      "2023-02-16 00:15:14,940 : INFO : sample=0.001 downsamples 47 most-common words\n",
      "2023-02-16 00:15:14,941 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 4500851.640108086 word corpus (76.0%% of prior 5924674)', 'datetime': '2023-02-16T00:15:14.941195', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2023-02-16 00:15:15,165 : INFO : estimated required memory for 33359 words and 100 dimensions: 43366700 bytes\n",
      "2023-02-16 00:15:15,165 : INFO : resetting layer weights\n",
      "2023-02-16 00:15:15,179 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-02-16T00:15:15.179256', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2023-02-16 00:15:15,179 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 33359 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-02-16T00:15:15.179753', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2023-02-16 00:15:16,186 : INFO : EPOCH 1 - PROGRESS: at 35.36% examples, 1599807 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:15:17,187 : INFO : EPOCH 1 - PROGRESS: at 71.82% examples, 1612966 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:15:17,951 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-02-16 00:15:17,960 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-02-16 00:15:17,962 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-02-16 00:15:17,963 : INFO : EPOCH - 1 : training on 6022875 raw words (4500700 effective words) took 2.8s, 1618162 effective words/s\n",
      "2023-02-16 00:15:18,968 : INFO : EPOCH 2 - PROGRESS: at 35.36% examples, 1599060 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:15:19,971 : INFO : EPOCH 2 - PROGRESS: at 71.30% examples, 1600564 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:15:20,762 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-02-16 00:15:20,771 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-02-16 00:15:20,774 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-02-16 00:15:20,774 : INFO : EPOCH - 2 : training on 6022875 raw words (4500307 effective words) took 2.8s, 1601285 effective words/s\n",
      "2023-02-16 00:15:21,778 : INFO : EPOCH 3 - PROGRESS: at 34.88% examples, 1583135 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:15:22,785 : INFO : EPOCH 3 - PROGRESS: at 70.28% examples, 1577845 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:15:23,629 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-02-16 00:15:23,638 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-02-16 00:15:23,641 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-02-16 00:15:23,641 : INFO : EPOCH - 3 : training on 6022875 raw words (4500732 effective words) took 2.9s, 1571411 effective words/s\n",
      "2023-02-16 00:15:24,646 : INFO : EPOCH 4 - PROGRESS: at 34.72% examples, 1574040 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:15:25,646 : INFO : EPOCH 4 - PROGRESS: at 69.77% examples, 1571946 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:15:26,488 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-02-16 00:15:26,496 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-02-16 00:15:26,499 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-02-16 00:15:26,499 : INFO : EPOCH - 4 : training on 6022875 raw words (4500772 effective words) took 2.9s, 1576395 effective words/s\n",
      "2023-02-16 00:15:27,507 : INFO : EPOCH 5 - PROGRESS: at 34.36% examples, 1554915 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:15:28,509 : INFO : EPOCH 5 - PROGRESS: at 69.96% examples, 1572032 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:15:29,361 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-02-16 00:15:29,369 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-02-16 00:15:29,372 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-02-16 00:15:29,372 : INFO : EPOCH - 5 : training on 6022875 raw words (4500626 effective words) took 2.9s, 1568094 effective words/s\n",
      "2023-02-16 00:15:29,372 : INFO : Word2Vec lifecycle event {'msg': 'training on 30114375 raw words (22503137 effective words) took 14.2s, 1585477 effective words/s', 'datetime': '2023-02-16T00:15:29.372702', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2023-02-16 00:15:29,373 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=33359, vector_size=100, alpha=0.025)', 'datetime': '2023-02-16T00:15:29.373091', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "w2v_cbow = gensim.models.word2vec.Word2Vec(sentences=text,\n",
    "                                vector_size=100, window=5,               ### here we train a cbow model \n",
    "                                min_count=5,                      \n",
    "                                sample=0.001, workers=3,\n",
    "                                sg=0, hs=0, negative=5,        ### set sg to 1 to train a sg model\n",
    "                                cbow_mean=1, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benkabongo25/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/benkabongo25/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/benkabongo25/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/benkabongo25/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/benkabongo25/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/benkabongo25/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/benkabongo25/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/benkabongo25/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/benkabongo25/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/benkabongo25/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "f_names = ['sum', 'mean', 'min', 'max']\n",
    "m_names = ['SG', 'CBOW', 'Pre_trained']\n",
    "\n",
    "scores = np.zeros((4, 3))\n",
    "\n",
    "for fi, f in enumerate([np.sum, np.mean, np.min, np.max]):\n",
    "    for mi, m in enumerate([w2v_sg.wv, w2v_cbow.wv, wv_pre_trained]):\n",
    "        scores[fi, mi] = vectorize_train_test(f, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum\n",
      "\t SG : 0.63072\n",
      "\t CBOW : 0.62176\n",
      "\t Pre_trained : 0.62832\n",
      "mean\n",
      "\t SG : 0.60324\n",
      "\t CBOW : 0.61224\n",
      "\t Pre_trained : 0.6118\n",
      "min\n",
      "\t SG : 0.55156\n",
      "\t CBOW : 0.5482\n",
      "\t Pre_trained : 0.5644\n",
      "max\n",
      "\t SG : 0.54976\n",
      "\t CBOW : 0.53988\n",
      "\t Pre_trained : 0.56132\n"
     ]
    }
   ],
   "source": [
    "for fi in range(4):\n",
    "    print(f_names[fi])\n",
    "    for mi in range(3):\n",
    "        print('\\t', m_names[mi], ':', scores[fi, mi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "plt.title('Word2Vec - Functions - Scores')\n",
    "for fi in range(4):\n",
    "    plt.plot(m_names, scores[fi], label=f_names[fi])\n",
    "plt.xlabel('Word2Vec')\n",
    "plt.ylabel('Scores')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**(Bonus)** To have a better accuracy, we could try two things:\n",
    "- Better aggregation methods (weight by tf-idf ?)\n",
    "- Another word vectorizing method such as [fasttext](https://radimrehurek.com/gensim/models/fasttext.html)\n",
    "- A document vectorizing method such as [Doc2Vec](https://radimrehurek.com/gensim/models/doc2vec.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 00:44:03,967 : INFO : collecting all words and their counts\n",
      "2023-02-16 00:44:03,968 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-02-16 00:44:04,248 : INFO : PROGRESS: at sentence #10000, processed 2426102 words, keeping 61702 word types\n",
      "2023-02-16 00:44:04,520 : INFO : PROGRESS: at sentence #20000, processed 4816878 words, keeping 84298 word types\n",
      "2023-02-16 00:44:04,662 : INFO : collected 93201 word types from a corpus of 6022875 raw words and 25000 sentences\n",
      "2023-02-16 00:44:04,662 : INFO : Creating a fresh vocabulary\n",
      "2023-02-16 00:44:04,750 : INFO : FastText lifecycle event {'msg': 'effective_min_count=5 retains 33359 unique words (35.79253441486679%% of original 93201, drops 59842)', 'datetime': '2023-02-16T00:44:04.750266', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2023-02-16 00:44:04,750 : INFO : FastText lifecycle event {'msg': 'effective_min_count=5 leaves 5924674 word corpus (98.36953282277982%% of original 6022875, drops 98201)', 'datetime': '2023-02-16T00:44:04.750689', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2023-02-16 00:44:04,865 : INFO : deleting the raw counts dictionary of 93201 items\n",
      "2023-02-16 00:44:04,867 : INFO : sample=0.001 downsamples 47 most-common words\n",
      "2023-02-16 00:44:04,867 : INFO : FastText lifecycle event {'msg': 'downsampling leaves estimated 4500851.640108086 word corpus (76.0%% of prior 5924674)', 'datetime': '2023-02-16T00:44:04.867717', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2023-02-16 00:44:05,277 : INFO : estimated required memory for 33359 words, 2000000 buckets and 100 dimensions: 849607464 bytes\n",
      "2023-02-16 00:44:05,278 : INFO : resetting layer weights\n",
      "2023-02-16 00:44:07,439 : INFO : FastText lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-02-16T00:44:07.439882', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2023-02-16 00:44:07,440 : INFO : FastText lifecycle event {'msg': 'training model with 3 workers on 33359 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-02-16T00:44:07.440580', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2023-02-16 00:44:08,460 : INFO : EPOCH 1 - PROGRESS: at 7.74% examples, 352476 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:09,473 : INFO : EPOCH 1 - PROGRESS: at 16.18% examples, 361412 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:10,477 : INFO : EPOCH 1 - PROGRESS: at 24.61% examples, 366435 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:11,487 : INFO : EPOCH 1 - PROGRESS: at 32.60% examples, 364934 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:12,496 : INFO : EPOCH 1 - PROGRESS: at 40.91% examples, 365796 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:13,510 : INFO : EPOCH 1 - PROGRESS: at 48.97% examples, 366239 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:14,530 : INFO : EPOCH 1 - PROGRESS: at 57.67% examples, 368343 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:15,543 : INFO : EPOCH 1 - PROGRESS: at 66.18% examples, 369513 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:16,562 : INFO : EPOCH 1 - PROGRESS: at 75.07% examples, 370745 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:17,585 : INFO : EPOCH 1 - PROGRESS: at 83.63% examples, 371184 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:18,588 : INFO : EPOCH 1 - PROGRESS: at 91.82% examples, 371474 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:19,473 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-02-16 00:44:19,522 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-02-16 00:44:19,526 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-02-16 00:44:19,526 : INFO : EPOCH - 1 : training on 6022875 raw words (4501315 effective words) took 12.1s, 372504 effective words/s\n",
      "2023-02-16 00:44:20,542 : INFO : EPOCH 2 - PROGRESS: at 7.74% examples, 354309 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:21,543 : INFO : EPOCH 2 - PROGRESS: at 14.50% examples, 327998 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:22,566 : INFO : EPOCH 2 - PROGRESS: at 21.98% examples, 327805 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:23,571 : INFO : EPOCH 2 - PROGRESS: at 29.17% examples, 327565 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:24,622 : INFO : EPOCH 2 - PROGRESS: at 36.36% examples, 324034 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:25,635 : INFO : EPOCH 2 - PROGRESS: at 42.95% examples, 318277 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:26,669 : INFO : EPOCH 2 - PROGRESS: at 49.45% examples, 314276 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:27,685 : INFO : EPOCH 2 - PROGRESS: at 56.38% examples, 312866 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:28,688 : INFO : EPOCH 2 - PROGRESS: at 63.21% examples, 313061 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:29,696 : INFO : EPOCH 2 - PROGRESS: at 70.71% examples, 313809 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:30,698 : INFO : EPOCH 2 - PROGRESS: at 78.57% examples, 316486 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:31,721 : INFO : EPOCH 2 - PROGRESS: at 85.98% examples, 317724 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:32,740 : INFO : EPOCH 2 - PROGRESS: at 93.84% examples, 319998 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:33,429 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-02-16 00:44:33,480 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-02-16 00:44:33,485 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-02-16 00:44:33,485 : INFO : EPOCH - 2 : training on 6022875 raw words (4500239 effective words) took 14.0s, 322441 effective words/s\n",
      "2023-02-16 00:44:34,490 : INFO : EPOCH 3 - PROGRESS: at 7.39% examples, 342522 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:35,492 : INFO : EPOCH 3 - PROGRESS: at 15.31% examples, 347394 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:36,504 : INFO : EPOCH 3 - PROGRESS: at 23.25% examples, 348863 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:37,512 : INFO : EPOCH 3 - PROGRESS: at 30.84% examples, 346993 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:38,526 : INFO : EPOCH 3 - PROGRESS: at 38.16% examples, 343550 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:39,539 : INFO : EPOCH 3 - PROGRESS: at 45.43% examples, 340509 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:40,540 : INFO : EPOCH 3 - PROGRESS: at 52.30% examples, 336873 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:41,564 : INFO : EPOCH 3 - PROGRESS: at 59.65% examples, 334149 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:42,570 : INFO : EPOCH 3 - PROGRESS: at 66.70% examples, 331992 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:43,588 : INFO : EPOCH 3 - PROGRESS: at 73.75% examples, 328939 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:44,611 : INFO : EPOCH 3 - PROGRESS: at 80.95% examples, 327148 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:45,637 : INFO : EPOCH 3 - PROGRESS: at 87.93% examples, 326213 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:46,656 : INFO : EPOCH 3 - PROGRESS: at 95.18% examples, 325613 words/s, in_qsize 6, out_qsize 0\n",
      "2023-02-16 00:44:47,292 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-02-16 00:44:47,347 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-02-16 00:44:47,352 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-02-16 00:44:47,352 : INFO : EPOCH - 3 : training on 6022875 raw words (4501495 effective words) took 13.9s, 324637 effective words/s\n",
      "2023-02-16 00:44:48,364 : INFO : EPOCH 4 - PROGRESS: at 6.75% examples, 311892 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 00:44:49,372 : INFO : EPOCH 4 - PROGRESS: at 14.36% examples, 323838 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:50,374 : INFO : EPOCH 4 - PROGRESS: at 21.82% examples, 327356 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:51,379 : INFO : EPOCH 4 - PROGRESS: at 29.00% examples, 327287 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:52,389 : INFO : EPOCH 4 - PROGRESS: at 36.19% examples, 326419 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:53,406 : INFO : EPOCH 4 - PROGRESS: at 43.60% examples, 326073 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:54,411 : INFO : EPOCH 4 - PROGRESS: at 50.57% examples, 325450 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:55,436 : INFO : EPOCH 4 - PROGRESS: at 58.21% examples, 325877 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:56,440 : INFO : EPOCH 4 - PROGRESS: at 65.35% examples, 325446 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:57,458 : INFO : EPOCH 4 - PROGRESS: at 72.83% examples, 324567 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:58,496 : INFO : EPOCH 4 - PROGRESS: at 80.29% examples, 324031 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:44:59,499 : INFO : EPOCH 4 - PROGRESS: at 87.34% examples, 323891 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:45:00,550 : INFO : EPOCH 4 - PROGRESS: at 94.34% examples, 322128 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:45:01,262 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-02-16 00:45:01,320 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-02-16 00:45:01,325 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-02-16 00:45:01,325 : INFO : EPOCH - 4 : training on 6022875 raw words (4500947 effective words) took 14.0s, 322187 effective words/s\n",
      "2023-02-16 00:45:02,375 : INFO : EPOCH 5 - PROGRESS: at 6.75% examples, 299536 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:45:03,410 : INFO : EPOCH 5 - PROGRESS: at 14.19% examples, 309632 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:45:04,434 : INFO : EPOCH 5 - PROGRESS: at 21.45% examples, 312921 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:45:05,458 : INFO : EPOCH 5 - PROGRESS: at 28.69% examples, 314891 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:45:06,481 : INFO : EPOCH 5 - PROGRESS: at 35.86% examples, 315815 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:45:07,511 : INFO : EPOCH 5 - PROGRESS: at 43.27% examples, 316445 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:45:08,524 : INFO : EPOCH 5 - PROGRESS: at 50.24% examples, 316752 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:45:09,526 : INFO : EPOCH 5 - PROGRESS: at 57.49% examples, 317359 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:45:10,534 : INFO : EPOCH 5 - PROGRESS: at 64.46% examples, 316980 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:45:11,557 : INFO : EPOCH 5 - PROGRESS: at 71.82% examples, 316153 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:45:12,566 : INFO : EPOCH 5 - PROGRESS: at 78.92% examples, 315806 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:45:13,623 : INFO : EPOCH 5 - PROGRESS: at 85.98% examples, 315002 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:45:14,629 : INFO : EPOCH 5 - PROGRESS: at 92.79% examples, 314483 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 00:45:15,555 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-02-16 00:45:15,614 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-02-16 00:45:15,620 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-02-16 00:45:15,620 : INFO : EPOCH - 5 : training on 6022875 raw words (4499807 effective words) took 14.3s, 314800 effective words/s\n",
      "2023-02-16 00:45:15,621 : INFO : FastText lifecycle event {'msg': 'training on 30114375 raw words (22503803 effective words) took 68.2s, 330051 effective words/s', 'datetime': '2023-02-16T00:45:15.621237', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2023-02-16 00:45:16,516 : INFO : FastText lifecycle event {'params': 'FastText(vocab=33359, vector_size=100, alpha=0.025)', 'datetime': '2023-02-16T00:45:16.516409', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# fasttext\n",
    "ft = gensim.models.FastText(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great and good: 0.7687962\n",
      "great and bad: 0.5416878\n"
     ]
    }
   ],
   "source": [
    "print(\"great and good:\",ft.wv.similarity(\"great\",\"good\"))\n",
    "print(\"great and bad:\",ft.wv.similarity(\"great\",\"bad\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie :\n",
      "\t ('moovie', 0.96757572889328)\n",
      "\t ('film', 0.9341885447502136)\n",
      "\t ('telemovie', 0.9299285411834717)\n",
      "\t ('moviegoer', 0.9175208806991577)\n",
      "\t ('microfilm', 0.8816311955451965)\n",
      "awesome :\n",
      "\t ('Awesome', 0.9397410154342651)\n",
      "\t ('awsome', 0.8085961937904358)\n",
      "\t ('gruesome', 0.8025217652320862)\n",
      "\t ('tiresome', 0.7847380638122559)\n",
      "\t ('amazing', 0.7798058986663818)\n",
      "actor :\n",
      "\t ('Factor', 0.920687735080719)\n",
      "\t ('tractor', 0.8570579290390015)\n",
      "\t ('Contractor', 0.8470588326454163)\n",
      "\t ('benefactor', 0.8426493406295776)\n",
      "\t ('actress', 0.8383766412734985)\n"
     ]
    }
   ],
   "source": [
    "for word in ['movie', 'awesome', 'actor']:\n",
    "    print(word, ':')\n",
    "    for item in ft.wv.most_similar(word,topn=5):\n",
    "        print('\\t', item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benkabongo25/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.59228"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_train_test(np.sum, ft.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benkabongo25/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.59196"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_train_test(np.mean, ft.wv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 09:48:57,615 : INFO : collecting all words and their counts\n",
      "2023-02-16 09:48:57,616 : WARNING : Each 'words' should be a list of words (usually unicode strings). First 'words' here is instead plain <class 'str'>.\n",
      "2023-02-16 09:48:57,616 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2023-02-16 09:48:58,550 : INFO : PROGRESS: at example #10000, processed 13421008 words (14388678/s), 163 word types, 0 tags\n",
      "2023-02-16 09:48:59,458 : INFO : PROGRESS: at example #20000, processed 26524225 words (14423886/s), 174 word types, 0 tags\n",
      "2023-02-16 09:48:59,918 : INFO : collected 178 word types and 25000 unique tags from a corpus of 25000 examples and 33126715 words\n",
      "2023-02-16 09:48:59,918 : INFO : Creating a fresh vocabulary\n",
      "2023-02-16 09:48:59,919 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 147 unique words (82.58426966292134%% of original 178, drops 31)', 'datetime': '2023-02-16T09:48:59.919687', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2023-02-16 09:48:59,919 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 33126655 word corpus (99.9998188773019%% of original 33126715, drops 60)', 'datetime': '2023-02-16T09:48:59.919971', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2023-02-16 09:48:59,921 : INFO : deleting the raw counts dictionary of 178 items\n",
      "2023-02-16 09:48:59,921 : INFO : sample=0.001 downsamples 31 most-common words\n",
      "2023-02-16 09:48:59,921 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 7201799.570360168 word corpus (21.7%% of prior 33126655)', 'datetime': '2023-02-16T09:48:59.921918', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2023-02-16 09:48:59,923 : INFO : estimated required memory for 147 words and 100 dimensions: 15191100 bytes\n",
      "2023-02-16 09:48:59,924 : INFO : resetting layer weights\n",
      "2023-02-16 09:48:59,937 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 147 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-02-16T09:48:59.937770', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2023-02-16 09:49:00,943 : INFO : EPOCH 1 - PROGRESS: at 18.30% examples, 1338447 words/s, in_qsize 6, out_qsize 0\n",
      "2023-02-16 09:49:01,943 : INFO : EPOCH 1 - PROGRESS: at 36.49% examples, 1334550 words/s, in_qsize 4, out_qsize 0\n",
      "2023-02-16 09:49:02,944 : INFO : EPOCH 1 - PROGRESS: at 54.82% examples, 1334215 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 09:49:03,944 : INFO : EPOCH 1 - PROGRESS: at 73.85% examples, 1336741 words/s, in_qsize 6, out_qsize 0\n",
      "2023-02-16 09:49:04,945 : INFO : EPOCH 1 - PROGRESS: at 92.43% examples, 1337366 words/s, in_qsize 5, out_qsize 1\n",
      "2023-02-16 09:49:05,341 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-02-16 09:49:05,342 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-02-16 09:49:05,342 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-02-16 09:49:05,342 : INFO : EPOCH - 1 : training on 33126715 raw words (7227137 effective words) took 5.4s, 1338015 effective words/s\n",
      "2023-02-16 09:49:06,345 : INFO : EPOCH 2 - PROGRESS: at 17.90% examples, 1310341 words/s, in_qsize 6, out_qsize 0\n",
      "2023-02-16 09:49:07,347 : INFO : EPOCH 2 - PROGRESS: at 35.86% examples, 1311781 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 09:49:08,347 : INFO : EPOCH 2 - PROGRESS: at 54.20% examples, 1320835 words/s, in_qsize 6, out_qsize 0\n",
      "2023-02-16 09:49:09,349 : INFO : EPOCH 2 - PROGRESS: at 73.20% examples, 1324284 words/s, in_qsize 6, out_qsize 0\n",
      "2023-02-16 09:49:10,350 : INFO : EPOCH 2 - PROGRESS: at 91.73% examples, 1327713 words/s, in_qsize 6, out_qsize 0\n",
      "2023-02-16 09:49:10,780 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-02-16 09:49:10,782 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-02-16 09:49:10,783 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-02-16 09:49:10,783 : INFO : EPOCH - 2 : training on 33126715 raw words (7229051 effective words) took 5.4s, 1328888 effective words/s\n",
      "2023-02-16 09:49:11,785 : INFO : EPOCH 3 - PROGRESS: at 18.24% examples, 1332188 words/s, in_qsize 6, out_qsize 0\n",
      "2023-02-16 09:49:12,785 : INFO : EPOCH 3 - PROGRESS: at 36.06% examples, 1319971 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 09:49:13,786 : INFO : EPOCH 3 - PROGRESS: at 54.21% examples, 1321704 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 09:49:14,789 : INFO : EPOCH 3 - PROGRESS: at 73.12% examples, 1322264 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 09:49:15,789 : INFO : EPOCH 3 - PROGRESS: at 91.32% examples, 1320956 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 09:49:16,244 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-02-16 09:49:16,244 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-02-16 09:49:16,245 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-02-16 09:49:16,245 : INFO : EPOCH - 3 : training on 33126715 raw words (7222837 effective words) took 5.5s, 1322746 effective words/s\n",
      "2023-02-16 09:49:17,248 : INFO : EPOCH 4 - PROGRESS: at 18.26% examples, 1331833 words/s, in_qsize 5, out_qsize 1\n",
      "2023-02-16 09:49:18,251 : INFO : EPOCH 4 - PROGRESS: at 36.61% examples, 1335754 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 09:49:19,252 : INFO : EPOCH 4 - PROGRESS: at 55.08% examples, 1338249 words/s, in_qsize 6, out_qsize 0\n",
      "2023-02-16 09:49:20,252 : INFO : EPOCH 4 - PROGRESS: at 74.08% examples, 1339282 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 09:49:21,253 : INFO : EPOCH 4 - PROGRESS: at 92.62% examples, 1339215 words/s, in_qsize 6, out_qsize 1\n",
      "2023-02-16 09:49:21,634 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-02-16 09:49:21,635 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-02-16 09:49:21,636 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-02-16 09:49:21,636 : INFO : EPOCH - 4 : training on 33126715 raw words (7224990 effective words) took 5.4s, 1340302 effective words/s\n",
      "2023-02-16 09:49:22,640 : INFO : EPOCH 5 - PROGRESS: at 18.35% examples, 1340021 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 09:49:23,640 : INFO : EPOCH 5 - PROGRESS: at 36.45% examples, 1333237 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 09:49:24,642 : INFO : EPOCH 5 - PROGRESS: at 54.60% examples, 1328700 words/s, in_qsize 6, out_qsize 0\n",
      "2023-02-16 09:49:25,642 : INFO : EPOCH 5 - PROGRESS: at 73.34% examples, 1326167 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 09:49:26,645 : INFO : EPOCH 5 - PROGRESS: at 91.92% examples, 1328686 words/s, in_qsize 6, out_qsize 2\n",
      "2023-02-16 09:49:27,063 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-02-16 09:49:27,064 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-02-16 09:49:27,064 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-02-16 09:49:27,065 : INFO : EPOCH - 5 : training on 33126715 raw words (7222568 effective words) took 5.4s, 1330813 effective words/s\n",
      "2023-02-16 09:49:28,069 : INFO : EPOCH 6 - PROGRESS: at 18.30% examples, 1338837 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 09:49:29,069 : INFO : EPOCH 6 - PROGRESS: at 36.51% examples, 1336472 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 09:49:30,070 : INFO : EPOCH 6 - PROGRESS: at 55.00% examples, 1338706 words/s, in_qsize 6, out_qsize 0\n",
      "2023-02-16 09:49:31,071 : INFO : EPOCH 6 - PROGRESS: at 74.06% examples, 1340362 words/s, in_qsize 6, out_qsize 0\n",
      "2023-02-16 09:49:32,072 : INFO : EPOCH 6 - PROGRESS: at 92.59% examples, 1339969 words/s, in_qsize 5, out_qsize 1\n",
      "2023-02-16 09:49:32,460 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-02-16 09:49:32,461 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 09:49:32,463 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-02-16 09:49:32,463 : INFO : EPOCH - 6 : training on 33126715 raw words (7228642 effective words) took 5.4s, 1339671 effective words/s\n",
      "2023-02-16 09:49:33,467 : INFO : EPOCH 7 - PROGRESS: at 17.88% examples, 1307155 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 09:49:34,467 : INFO : EPOCH 7 - PROGRESS: at 35.92% examples, 1314184 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 09:49:35,468 : INFO : EPOCH 7 - PROGRESS: at 54.29% examples, 1323443 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 09:49:36,469 : INFO : EPOCH 7 - PROGRESS: at 73.43% examples, 1329329 words/s, in_qsize 6, out_qsize 0\n",
      "2023-02-16 09:49:37,470 : INFO : EPOCH 7 - PROGRESS: at 92.04% examples, 1331951 words/s, in_qsize 6, out_qsize 0\n",
      "2023-02-16 09:49:37,885 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-02-16 09:49:37,885 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-02-16 09:49:37,887 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-02-16 09:49:37,887 : INFO : EPOCH - 7 : training on 33126715 raw words (7228970 effective words) took 5.4s, 1333124 effective words/s\n",
      "2023-02-16 09:49:38,890 : INFO : EPOCH 8 - PROGRESS: at 18.30% examples, 1337043 words/s, in_qsize 6, out_qsize 0\n",
      "2023-02-16 09:49:39,890 : INFO : EPOCH 8 - PROGRESS: at 36.60% examples, 1337870 words/s, in_qsize 6, out_qsize 0\n",
      "2023-02-16 09:49:40,891 : INFO : EPOCH 8 - PROGRESS: at 54.60% examples, 1329537 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 09:49:41,891 : INFO : EPOCH 8 - PROGRESS: at 73.59% examples, 1332306 words/s, in_qsize 6, out_qsize 0\n",
      "2023-02-16 09:49:42,891 : INFO : EPOCH 8 - PROGRESS: at 92.08% examples, 1332535 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 09:49:43,305 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-02-16 09:49:43,307 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-02-16 09:49:43,308 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-02-16 09:49:43,308 : INFO : EPOCH - 8 : training on 33126715 raw words (7224812 effective words) took 5.4s, 1333033 effective words/s\n",
      "2023-02-16 09:49:44,310 : INFO : EPOCH 9 - PROGRESS: at 18.26% examples, 1334406 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 09:49:45,312 : INFO : EPOCH 9 - PROGRESS: at 36.62% examples, 1338493 words/s, in_qsize 5, out_qsize 1\n",
      "2023-02-16 09:49:46,313 : INFO : EPOCH 9 - PROGRESS: at 55.14% examples, 1340850 words/s, in_qsize 6, out_qsize 0\n",
      "2023-02-16 09:49:47,314 : INFO : EPOCH 9 - PROGRESS: at 74.15% examples, 1341384 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 09:49:48,315 : INFO : EPOCH 9 - PROGRESS: at 92.74% examples, 1341388 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 09:49:48,691 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-02-16 09:49:48,691 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-02-16 09:49:48,692 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-02-16 09:49:48,693 : INFO : EPOCH - 9 : training on 33126715 raw words (7227544 effective words) took 5.4s, 1342425 effective words/s\n",
      "2023-02-16 09:49:49,696 : INFO : EPOCH 10 - PROGRESS: at 18.24% examples, 1330941 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 09:49:50,697 : INFO : EPOCH 10 - PROGRESS: at 36.51% examples, 1334983 words/s, in_qsize 6, out_qsize 0\n",
      "2023-02-16 09:49:51,699 : INFO : EPOCH 10 - PROGRESS: at 54.96% examples, 1336681 words/s, in_qsize 5, out_qsize 0\n",
      "2023-02-16 09:49:52,699 : INFO : EPOCH 10 - PROGRESS: at 74.04% examples, 1339290 words/s, in_qsize 6, out_qsize 0\n",
      "2023-02-16 09:49:53,700 : INFO : EPOCH 10 - PROGRESS: at 92.69% examples, 1340598 words/s, in_qsize 6, out_qsize 0\n",
      "2023-02-16 09:49:54,078 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2023-02-16 09:49:54,079 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2023-02-16 09:49:54,080 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2023-02-16 09:49:54,080 : INFO : EPOCH - 10 : training on 33126715 raw words (7226707 effective words) took 5.4s, 1341697 effective words/s\n",
      "2023-02-16 09:49:54,080 : INFO : Doc2Vec lifecycle event {'msg': 'training on 331267150 raw words (72263258 effective words) took 54.1s, 1334638 effective words/s', 'datetime': '2023-02-16T09:49:54.080739', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2023-02-16 09:49:54,081 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec(dm/m,d100,n5,w5,mc5,s0.001,t3)', 'datetime': '2023-02-16T09:49:54.081123', 'gensim': '4.1.2', 'python': '3.9.13 (main, Aug 25 2022, 18:29:29) \\n[Clang 12.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "train_documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(train_df.text)]\n",
    "d2v = Doc2Vec(train_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.5604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benkabongo25/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "train_text = train_df.text.map(preprocess)\n",
    "test_text = test_df.text.map(preprocess)\n",
    "\n",
    "y = np.array(train_df.label)\n",
    "y_test = np.array(test_df.label)\n",
    "\n",
    "X = [d2v.infer_vector(t.split()) for t in train_text]\n",
    "X_test = [d2v.infer_vector(t.split()) for t in test_text]\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X, y)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "print('Accuracy :', accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = train_df.text.map(preprocess)\n",
    "test_corpus = test_df.text.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(lowercase=True)\n",
    "vectors = vectorizer.fit_transform(train_corpus)\n",
    "matrix = vectors.toarray()\n",
    "\n",
    "# features trick\n",
    "features = vectorizer.get_feature_names_out()\n",
    "# clé : mot, valeur : index\n",
    "vk_features = dict(zip(features, np.arange(0, len(features))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectors = vectorizer.transform(test_df.text)\n",
    "test_matrix = test_vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_tfidf(document_index, \n",
    "                    f=np.mean,\n",
    "                    corpus=train_df.text, \n",
    "                    matrix=matrix, \n",
    "                    vk_features=vk_features,\n",
    "                    model=wv_pre_trained):\n",
    "    \n",
    "    doc = corpus[document_index]\n",
    "    doc_matrix = matrix[document_index]\n",
    "    \n",
    "    vec = []\n",
    "    for word in doc:\n",
    "        if word.lower() in vk_features and word in model.key_to_index:\n",
    "            tf_idf_score = doc_matrix[ vk_features[word.lower()] ]\n",
    "            w2v_matrix = np.array(model[word])\n",
    "            vec.append( list( tf_idf_score * w2v_matrix ) )\n",
    "            \n",
    "    print(vec)\n",
    "    return f(vec, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [vectorize_tfidf(i) for i in range(len(train_corpus))]\n",
    "y = np.array(train_df.label)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [vectorize_tfidf(i, corpus=test_corpus, matrix=test_matrix) for i in range(len(test_corpus))]\n",
    "y_test = np.array(test_df.label)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "902a52bcf4503a473db011f1937bdfe17613b08622219712e0110e48c4958c23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
